{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the libraries which are used for importing the dataset and creating the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create static variables that will be used later. These variables consists of values such as the rate at which the network learns from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to rerun the training dataset\n",
    "epochs = 1\n",
    "\n",
    "# How many images to feed through the network each time\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "# Step size for gradiant decent\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Gives the network a chance to jump out of a local minima\n",
    "momentum = 0.5\n",
    "\n",
    "# Use a constant seed for randomness so that reruns becomes predictable\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code blocks provides the data set with handwritten digits. It converts the images into Pytorch tensors and normalizes the pixels into the range 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                             torchvision.transforms.Normalize((0.5,), (0.5,))])),batch_size=batch_size_train, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_set = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.5,), (0.5,))])),batch_size=batch_size_test, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line of code simply outputs the structure of the data. The output here shows that each batch in the training data contains 64 images and that each image has 28x28 pixels dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(training_set)\n",
    "_, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below plots different numbers from the dataset to show numbers and different ways people wrote them down. Each image has a ground truth which simply means what number does the image represent. This is a way to show that everyone has a different handwriting and the network should be capable of recognizing most of the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Label: {}\".format(example_targets[i]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function simply creates and returns a model that contains 3 layers: a 28x28 input layer, a hidden layer of 50 nodes and an output layer of size 10. The LogSoftmax is for normalizing the output vector to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block trains the network with the handwritten digit data (training_set). It iterates over an n amount of epochs. It also iterates over each batch from the training_set. At each iteration, it adjusts the weights as well as calculating the loss. This allows us to see how accurate is the prediction of each batch. The accuracy is stored in an array which helps to plot the training process of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    total = 0\n",
    "    nr_correct = 0\n",
    "\n",
    "    accuracies = []\n",
    "    for n in range(0, epochs):\n",
    "        for (batch_index, (images, labels)) in enumerate(training_set):\n",
    "            accuracy = model.fit(images, labels)\n",
    "            accuracies.append(accuracy)\n",
    "            \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this function create a test model which can be used to compare to the training model. It is used to check if the model generalized to the other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_set):\n",
    "    total = 0\n",
    "    nr_correct = 0\n",
    "    \n",
    "    for images, labels in test_set:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        result = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(result, 1)\n",
    "        total = images.size(0)\n",
    "        nr_correct = torch.sum(predictions == labels).item()\n",
    "                \n",
    "    return nr_correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function within the codeblock below uses the information obtained from the training to plot the rate at which the network learns about the data. The plot contains the amount of training batches and the accuracy of the model during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0a4d30153b23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyper_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Model, self).__init__()\n",
    "        self.hyper_params = hyper_params\n",
    "        \n",
    "        layers = []\n",
    "        for n in self.hyper_params['conv_layers']:\n",
    "            conv_layer = nn.Conv2d(\n",
    "                n['in_channels'], \n",
    "                n['out_channels'], \n",
    "                n['kernel_size']\n",
    "            )\n",
    "            layers.append(conv_layer)\n",
    "            layers.append(self.get_activation_function())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(len(self.hyper_params['regular_layers']) - 1):\n",
    "            nr_in = self.hyper_params['regular_layers'][i];\n",
    "            nr_out = self.hyper_params['regular_layers'][i + 1];\n",
    "            layers.append(nn.Linear(nr_in, nr_out))\n",
    "            layers.append(self.get_activation_function())\n",
    "        \n",
    "        # The output layer should not have an activation function\n",
    "        layers.pop()\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "          \n",
    "        learning_rate = self.hyper_params['learning_rate']\n",
    "        momentum = self.hyper_params['momentum']\n",
    "        optimizer = self.hyper_params['optimizer']\n",
    "        if optimizer == 'SGD':\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        elif optimizer == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            raise Exception('Invalid optimizer')\n",
    "            \n",
    "        criterion = self.hyper_params['criterion']\n",
    "        if criterion == 'CrossEntropy':\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise Exception('Invalid criterion')\n",
    "        \n",
    "        \n",
    "    def get_activation_function(self):\n",
    "        fun = self.hyper_params['activation_function']\n",
    "        if fun == 'ReLU':\n",
    "            return nn.ReLU()\n",
    "        if fun == 'Sigmoid':\n",
    "            return torch.nn.Sigmoid()\n",
    "        if fun == 'Swish':\n",
    "            return Swish()\n",
    "        \n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        tensor = self.conv(tensor)\n",
    "        tensor = tensor.reshape(tensor.size(0), -1)\n",
    "        return self.net(tensor)\n",
    "    \n",
    "    \n",
    "    def fit(self, tensor, labels):\n",
    "        tensor = tensor.to(device)\n",
    "        labels = labels.to(device)\n",
    "        result = self(tensor)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(result, labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        _, predictions = torch.max(result, 1)\n",
    "        total = tensor.size(0)\n",
    "        nr_correct = torch.sum(predictions == labels).item()\n",
    "        \n",
    "        return nr_correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BLOCK EXPLAINING THE MODEL*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_permutations():\n",
    "    layer_sizes = [32, 64, 128]\n",
    "    hidden_layers = [list(n) for n in itertools.permutations(layer_sizes, 1)]\\\n",
    "                  + [[a, b] for (a, b) in itertools.permutations(layer_sizes, 2) if a >= b]\n",
    "    \n",
    "    channel_sizes = [4, 8, 16]\n",
    "    conv_layers = [list(n) for n in itertools.permutations(channel_sizes, 1)]\\\n",
    "                + [[a, b] for (a, b) in itertools.permutations(channel_sizes, 2) if a <= b]\n",
    "    \n",
    "    kernel_sizes = [5]\n",
    "    activation_functions = ['ReLU', 'Sigmoid', 'Swish']\n",
    "    criterions = ['CrossEntropy']\n",
    "    \n",
    "    #Adding momentum directly to the optimizer since it's only used for SGD\n",
    "    optimizers = [('SGD', 0.1), ('SGD', 0.5), ('SGD', 1.0), 'Adam']\n",
    "    learning_rates = [0.1, 0.01, 0.001]\n",
    "\n",
    "    return itertools.product(\n",
    "        hidden_layers,\n",
    "        conv_layers,\n",
    "        kernel_sizes,\n",
    "        activation_functions,\n",
    "        criterions,\n",
    "        optimizers,\n",
    "        learning_rates\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, input_tensor):\n",
    "        return input_tensor * torch.sigmoid(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BLOCK EXPLAINING OUR CHOICE OF SEARCH PARAMS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_to_dictionary(hidden_layers, channel_sizes, kernel_size, act_fun, criterion, optimizer, learning_rate):\n",
    "    conv_layers = []\n",
    "    in_channels = 1\n",
    "    side_length = 28\n",
    "    for channel_size in channel_sizes:\n",
    "        out_channels = channel_size\n",
    "        conv_layers.append(\n",
    "            {\n",
    "                'in_channels': in_channels,\n",
    "                'out_channels': out_channels,\n",
    "                'kernel_size': kernel_size\n",
    "            }\n",
    "        )\n",
    "        in_channels = out_channels\n",
    "    \n",
    "        side_length -= kernel_size - 1\n",
    "        side_length //= 2\n",
    "        \n",
    "    if type(optimizer) is tuple:\n",
    "        momentum = optimizer[1]\n",
    "        optimizer = optimizer[0]\n",
    "    else:\n",
    "        momentum = 0\n",
    "    \n",
    "    regular_layers = [side_length * side_length * out_channels] + hidden_layers + [10]\n",
    "    return {\n",
    "        'conv_layers': conv_layers,\n",
    "        'regular_layers': regular_layers,\n",
    "        'activation_function': act_fun,\n",
    "        'optimizer': optimizer,\n",
    "        'criterion': criterion,\n",
    "        'learning_rate': learning_rate,\n",
    "        'momentum': momentum\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BLOCK EXPLAINING THIS FUNCTION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    gc.collect()\n",
    "    before = time.time()\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    permutations = list(hyper_parameter_permutations())\n",
    "    \n",
    "    print(\"Searching through {} permutations\".format(len(permutations)))\n",
    "\n",
    "    i = 0\n",
    "    for n in permutations:\n",
    "        grid_search_helper(n, models)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"{} complete, time elapsed: {:.2f} minutes\".format(i, (time.time() - before) / 60))\n",
    "            \n",
    "        if i % 500 == 0:\n",
    "            gc.collect()\n",
    "\n",
    "    models.sort(key=lambda n: n[0], reverse=True)\n",
    "\n",
    "    after = time.time()\n",
    "    print(\"Done, took {:.2f} minutes\".format((after - before) / 60))\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Wrapper function that allows garbage collector to run\n",
    "def grid_search_helper(permutation, models):\n",
    "    hyper_params = permutation_to_dictionary(*permutation)\n",
    "    model = Model(hyper_params)\n",
    "    model.to(device)\n",
    "    train_model(model)\n",
    "    accuracy = test_model(model, test_set)\n",
    "    models.append((accuracy, model.hyper_params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BLOCK EXPLAINING THE GRID SEARCH*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(models, filename):\n",
    "    params = [(accuracy, model) for (accuracy, model) in models]\n",
    "    params_json = json.dumps(params)\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(params_json)\n",
    "    f.close()\n",
    "    \n",
    "def load_models(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    params = json.loads(f.read())\n",
    "    f.close()\n",
    "    return [(accuracy, Model(hp)) for (accuracy, hp) in params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BLOCK EXPLAINING THE SAVE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching through 1296 permutations\n",
      "100 complete, time elapsed: 10.53 minutes\n",
      "200 complete, time elapsed: 22.87 minutes\n",
      "300 complete, time elapsed: 33.82 minutes\n",
      "400 complete, time elapsed: 45.93 minutes\n",
      "500 complete, time elapsed: 57.15 minutes\n",
      "600 complete, time elapsed: 68.93 minutes\n",
      "700 complete, time elapsed: 81.25 minutes\n",
      "800 complete, time elapsed: 94.20 minutes\n",
      "900 complete, time elapsed: 107.75 minutes\n",
      "1000 complete, time elapsed: 120.51 minutes\n",
      "1100 complete, time elapsed: 134.29 minutes\n",
      "1200 complete, time elapsed: 146.82 minutes\n",
      "Done, took 160.52 minutes\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "models = grid_search()\n",
    "save_models(models, \"one_epoch_models.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BLOCK ABOUT RUNNING IT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

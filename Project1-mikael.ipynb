{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the libraries which are used for importing the dataset and creating the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create static variables that will be used later. These variables consists of values such as the rate at which the network learns from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to rerun the training dataset\n",
    "epochs = 1\n",
    "\n",
    "# How many images to feed through the network each time\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "# Step size for gradiant decent\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Gives the network a chance to jump out of a local minima\n",
    "momentum = 0.5\n",
    "\n",
    "# Use a constant seed for randomness so that reruns becomes predictable\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code blocks provides the data set with handwritten digits. It converts the images into Pytorch tensors and normalizes the pixels into the range 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                             torchvision.transforms.Normalize((0.5,), (0.5,))])),batch_size=batch_size_train, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_set = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.5,), (0.5,))])),batch_size=batch_size_test, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line of code simply outputs the structure of the data. The output here shows that each batch in the training data contains 64 images and that each image has 28x28 pixels dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(training_set)\n",
    "_, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below plots different numbers from the dataset to show numbers and different ways people wrote them down. Each image has a ground truth which simply means what number does the image represent. This is a way to show that everyone has a different handwriting and the network should be capable of recognizing most of the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Label: {}\".format(example_targets[i]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function simply creates and returns a model that contains 3 layers: a 28x28 input layer, a hidden layer of 50 nodes and an output layer of size 10. The LogSoftmax is for normalizing the output vector to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block trains the network with the handwritten digit data (training_set). It iterates over an n amount of epochs. It also iterates over each batch from the training_set. At each iteration, it adjusts the weights as well as calculating the loss. This allows us to see how accurate is the prediction of each batch. The accuracy is stored in an array which helps to plot the training process of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    total = 0\n",
    "    nr_correct = 0\n",
    "\n",
    "    accuracies = []\n",
    "    for n in range(0, epochs):\n",
    "        for (batch_index, (images, labels)) in enumerate(training_set):\n",
    "            accuracy = model.fit(images, labels)\n",
    "            accuracies.append(accuracy)\n",
    "            \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this function create a test model which can be used to compare to the training model. It is used to check if the model generalized to the other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_set):\n",
    "    total = 0\n",
    "    nr_correct = 0\n",
    "    \n",
    "    for images, labels in test_set:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        result = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(result, 1)\n",
    "        total = images.size(0)\n",
    "        nr_correct = torch.sum(predictions == labels).item()\n",
    "                \n",
    "    return nr_correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function within the codeblock below uses the information obtained from the training to plot the rate at which the network learns about the data. The plot contains the amount of training batches and the accuracy of the model during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Model, self).__init__()\n",
    "        self.hyper_params = hyper_params\n",
    "        \n",
    "        layers = []\n",
    "        for n in self.hyper_params['conv_layers']:\n",
    "            conv_layer = nn.Conv2d(\n",
    "                n['in_channels'], \n",
    "                n['out_channels'], \n",
    "                n['kernel_size']\n",
    "            )\n",
    "            layers.append(conv_layer)\n",
    "            layers.append(self.get_activation_function())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(len(self.hyper_params['regular_layers']) - 1):\n",
    "            nr_in = self.hyper_params['regular_layers'][i];\n",
    "            nr_out = self.hyper_params['regular_layers'][i + 1];\n",
    "            layers.append(nn.Linear(nr_in, nr_out))\n",
    "            layers.append(self.get_activation_function())\n",
    "        \n",
    "        # The output layer should not have an activation function\n",
    "        layers.pop()\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "          \n",
    "        learning_rate = self.hyper_params['learning_rate']\n",
    "        momentum = self.hyper_params['momentum']\n",
    "        optimizer = self.hyper_params['optimizer']\n",
    "        if optimizer == 'SGD':\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        elif optimizer == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            raise Exception('Invalid optimizer')\n",
    "            \n",
    "        criterion = self.hyper_params['criterion']\n",
    "        if criterion == 'CrossEntropy':\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise Exception('Invalid criterion')\n",
    "        \n",
    "        \n",
    "    def get_activation_function(self):\n",
    "        fun = self.hyper_params['activation_function']\n",
    "        if fun == 'ReLU':\n",
    "            return nn.ReLU()\n",
    "        if fun == 'Sigmoid':\n",
    "            return torch.nn.Sigmoid()\n",
    "        if fun == 'Swish':\n",
    "            return Swish()\n",
    "        \n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        tensor = self.conv(tensor)\n",
    "        tensor = tensor.reshape(tensor.size(0), -1)\n",
    "        return self.net(tensor)\n",
    "    \n",
    "    \n",
    "    def fit(self, tensor, labels):\n",
    "        tensor = tensor.to(device)\n",
    "        labels = labels.to(device)\n",
    "        result = self(tensor)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(result, labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        _, predictions = torch.max(result, 1)\n",
    "        total = tensor.size(0)\n",
    "        nr_correct = torch.sum(predictions == labels).item()\n",
    "        \n",
    "        return nr_correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class constructs a model from a dictionary of hyper parameters which allows us to have a variable amount of convolutional layers, hidden layers and different activation functions etc. We've chosen to have a dictionary instead of multiple params to the constructor for an easy way to save, load and print the different models.\n",
    "\n",
    "forward:\n",
    "todo\n",
    "\n",
    "fit:\n",
    "todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_permutations():\n",
    "    layer_sizes = [32, 64, 128]\n",
    "    hidden_layers = [list(n) for n in itertools.permutations(layer_sizes, 1)]\\\n",
    "                  + [[a, b] for (a, b) in itertools.permutations(layer_sizes, 2) if a >= b]\n",
    "    \n",
    "    channel_sizes = [4, 8, 16]\n",
    "    conv_layers = [list(n) for n in itertools.permutations(channel_sizes, 1)]\\\n",
    "                + [[a, b] for (a, b) in itertools.permutations(channel_sizes, 2) if a <= b]\n",
    "    \n",
    "    kernel_sizes = [5]\n",
    "    activation_functions = ['ReLU', 'Sigmoid', 'Swish']\n",
    "    criterions = ['CrossEntropy']\n",
    "    \n",
    "    #Adding momentum directly to the optimizer since it's only used for SGD\n",
    "    optimizers = [('SGD', 0.1), ('SGD', 0.5), ('SGD', 1.0), 'Adam']\n",
    "    learning_rates = [0.1, 0.01, 0.001]\n",
    "\n",
    "    return itertools.product(\n",
    "        hidden_layers,\n",
    "        conv_layers,\n",
    "        kernel_sizes,\n",
    "        activation_functions,\n",
    "        criterions,\n",
    "        optimizers,\n",
    "        learning_rates\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, input_tensor):\n",
    "        return input_tensor * torch.sigmoid(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we got the initial params... todo\n",
    "\n",
    "Hidden layers and convolution layers:\n",
    "todo\n",
    "\n",
    "Kernel size:\n",
    "In order to reduce the amount of combinations we are only testing one kernel size.\n",
    "\n",
    "We are testing three different activation functions: Sigmoid, ReLU and Swish.\n",
    "Sigmoid bad\n",
    "ReLU everyone uses\n",
    "Swish new from google, supposedly good\n",
    "\n",
    "Criterions:\n",
    "Searching through the Internet for good loss functions for classification problems, we only found NLLLoss (The negative log likelihood loss) and Cross Entropy loss that worked with our existing model. Since Cross Entropy Loss is the same as NLLLoss and LogSoftMax @@EXPLAINATION@@ combined we are only using that one.\n",
    "\n",
    "Optimizers:\n",
    "todo\n",
    "\n",
    "Learning rates: \n",
    "todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_to_dictionary(hidden_layers, channel_sizes, kernel_size, act_fun, criterion, optimizer, learning_rate):\n",
    "    conv_layers = []\n",
    "    in_channels = 1\n",
    "    side_length = 28\n",
    "    for channel_size in channel_sizes:\n",
    "        out_channels = channel_size\n",
    "        conv_layers.append(\n",
    "            {\n",
    "                'in_channels': in_channels,\n",
    "                'out_channels': out_channels,\n",
    "                'kernel_size': kernel_size\n",
    "            }\n",
    "        )\n",
    "        in_channels = out_channels\n",
    "    \n",
    "        side_length -= kernel_size - 1\n",
    "        side_length //= 2\n",
    "        \n",
    "    if type(optimizer) is tuple:\n",
    "        momentum = optimizer[1]\n",
    "        optimizer = optimizer[0]\n",
    "    else:\n",
    "        momentum = 0\n",
    "    \n",
    "    regular_layers = [side_length * side_length * out_channels] + hidden_layers + [10]\n",
    "    return {\n",
    "        'conv_layers': conv_layers,\n",
    "        'regular_layers': regular_layers,\n",
    "        'activation_function': act_fun,\n",
    "        'optimizer': optimizer,\n",
    "        'criterion': criterion,\n",
    "        'learning_rate': learning_rate,\n",
    "        'momentum': momentum\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function converts the hyper parameter permutations to the dictionary format that we use to construct the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    gc.collect()\n",
    "    before = time.time()\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    permutations = list(hyper_parameter_permutations())\n",
    "    \n",
    "    print(\"Searching through {} permutations\".format(len(permutations)))\n",
    "\n",
    "    i = 0\n",
    "    for n in permutations:\n",
    "        grid_search_helper(n, models)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"{} complete, time elapsed: {:.2f} minutes\".format(i, (time.time() - before) / 60))\n",
    "            \n",
    "        if i % 500 == 0:\n",
    "            gc.collect()\n",
    "\n",
    "    models.sort(key=lambda n: n[0], reverse=True)\n",
    "\n",
    "    after = time.time()\n",
    "    print(\"Done, took {:.2f} minutes\".format((after - before) / 60))\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Wrapper function that allows garbage collector to run\n",
    "def grid_search_helper(permutation, models):\n",
    "    hyper_params = permutation_to_dictionary(*permutation)\n",
    "    model = Model(hyper_params)\n",
    "    model.to(device)\n",
    "    train_model(model)\n",
    "    accuracy = test_model(model, test_set)\n",
    "    models.append((accuracy, model.hyper_params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searches for the model with the highest accuracy by going though all permutations, constructing a model for each, training it and comparing the model to the test set. Then storing the models hyper parameters along with the accuracy in a sorted list from best to worst model. @TODO something about missing models with slow learning rate?@ @TODO something about running the garbage collector@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(params, filename):\n",
    "    params_json = json.dumps(params)\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(params_json)\n",
    "    f.close()\n",
    "    \n",
    "def read_json(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    params = json.loads(f.read())\n",
    "    f.close()\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we don't want to perform our lengthy grid search multiple times, we have a simple read/write to a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4d996a903645>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msave_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"one_epoch_models.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "models = grid_search()\n",
    "write_json(models, \"one_epoch_models.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BLOCK ABOUT RUNNING IT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter\n",
    "import json\n",
    "\n",
    "with open('./one_epoch_models.json') as f:\n",
    "    models_params_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.994,\n",
       " {'conv_layers': [{'in_channels': 1, 'out_channels': 8, 'kernel_size': 5},\n",
       "   {'in_channels': 8, 'out_channels': 16, 'kernel_size': 5}],\n",
       "  'regular_layers': [256, 128, 64, 10],\n",
       "  'activation_function': 'Swish',\n",
       "  'optimizer': 'SGD',\n",
       "  'criterion': 'CrossEntropy',\n",
       "  'learning_rate': 0.1,\n",
       "  'momentum': 0.5}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_params_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296\n"
     ]
    }
   ],
   "source": [
    "print(len(models_params_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_layers': [{'in_channels': 1, 'out_channels': 8, 'kernel_size': 5}, {'in_channels': 8, 'out_channels': 16, 'kernel_size': 5}], 'regular_layers': [256, 128, 64, 10], 'activation_function': 'Swish', 'optimizer': 'SGD', 'criterion': 'CrossEntropy', 'learning_rate': 0.1, 'momentum': 0.5}\n",
      "{'conv_layers': [{'in_channels': 1, 'out_channels': 8, 'kernel_size': 5}, {'in_channels': 8, 'out_channels': 16, 'kernel_size': 5}], 'regular_layers': [256, 128, 10], 'activation_function': 'ReLU', 'optimizer': 'SGD', 'criterion': 'CrossEntropy', 'learning_rate': 0.1, 'momentum': 0.5}\n",
      "{'conv_layers': [{'in_channels': 1, 'out_channels': 8, 'kernel_size': 5}, {'in_channels': 8, 'out_channels': 16, 'kernel_size': 5}], 'regular_layers': [256, 128, 32, 10], 'activation_function': 'Swish', 'optimizer': 'Adam', 'criterion': 'CrossEntropy', 'learning_rate': 0.001, 'momentum': 0}\n",
      "{'conv_layers': [{'in_channels': 1, 'out_channels': 8, 'kernel_size': 5}, {'in_channels': 8, 'out_channels': 16, 'kernel_size': 5}], 'regular_layers': [256, 32, 10], 'activation_function': 'Swish', 'optimizer': 'Adam', 'criterion': 'CrossEntropy', 'learning_rate': 0.001, 'momentum': 0}\n",
      "{'conv_layers': [{'in_channels': 1, 'out_channels': 4, 'kernel_size': 5}, {'in_channels': 4, 'out_channels': 16, 'kernel_size': 5}], 'regular_layers': [256, 32, 10], 'activation_function': 'Swish', 'optimizer': 'Adam', 'criterion': 'CrossEntropy', 'learning_rate': 0.01, 'momentum': 0}\n"
     ]
    }
   ],
   "source": [
    "show_top = 5\n",
    "for i in range(0, show_top):\n",
    "    print((models_params_data[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import heapq\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13369936830>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# How many images to feed through the network each time\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "# Step size for gradiant decent\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Gives the network a chance to jump out of a local minima\n",
    "momentum = 0.5\n",
    "\n",
    "# Use a constant seed for randomness so that reruns becomes predictable\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                             torchvision.transforms.Normalize((0.5,), (0.5,))])),batch_size=batch_size_train, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_set = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize((0.5,), (0.5,))])),batch_size=batch_size_test, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Model, self).__init__()\n",
    "        self.hyper_params = hyper_params\n",
    "        \n",
    "        layers = []\n",
    "        for n in self.hyper_params['conv_layers']:\n",
    "            conv_layer = nn.Conv2d(\n",
    "                n['in_channels'], \n",
    "                n['out_channels'], \n",
    "                n['kernel_size']\n",
    "            )\n",
    "            layers.append(conv_layer)\n",
    "            layers.append(self.get_activation_function())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(self.hyper_params['regular_layers']) - 1):\n",
    "            nr_in = self.hyper_params['regular_layers'][i];\n",
    "            nr_out = self.hyper_params['regular_layers'][i + 1];\n",
    "            layers.append(nn.Linear(nr_in, nr_out))\n",
    "            layers.append(self.get_activation_function())\n",
    "        \n",
    "        # The output layer should not have an activation function\n",
    "        layers.pop()\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "        learning_rate = self.hyper_params['learning_rate']\n",
    "        momentum = self.hyper_params['momentum']\n",
    "        optimizer = self.hyper_params['optimizer']\n",
    "        if optimizer == 'SGD':\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        elif optimizer == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            raise Exception('Invalid optimizer')\n",
    "            \n",
    "        criterion = self.hyper_params['criterion']\n",
    "        if criterion == 'CrossEntropy':\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise Exception('Invalid criterion')\n",
    "        \n",
    "        \n",
    "    def get_activation_function(self):\n",
    "        fun = self.hyper_params['activation_function']\n",
    "        if fun == 'ReLU':\n",
    "            return nn.ReLU()\n",
    "        if fun == 'Sigmoid':\n",
    "            return torch.nn.Sigmoid()\n",
    "        if fun == 'Swish':\n",
    "            return Swish()\n",
    "        \n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        tensor = self.conv(tensor)\n",
    "        tensor = tensor.reshape(tensor.size(0), -1)\n",
    "        return self.net(tensor)\n",
    "    \n",
    "    \n",
    "    def fit(self, tensor, labels):\n",
    "       \n",
    "        result = self(tensor)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(result, labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        _, predictions = torch.max(result, 1)\n",
    "        total = tensor.size(0)\n",
    "        nr_correct = torch.sum(predictions == labels).item()\n",
    "        \n",
    "        return nr_correct / total\n",
    "    \n",
    "    \n",
    "    #Needed to not compare models stored in a tuple\n",
    "    def __lt__(self, m):\n",
    "        return False\n",
    "    \n",
    "    \n",
    "class Swish(nn.Module):\n",
    "    def forward(self, input_tensor):\n",
    "        return input_tensor * torch.sigmoid(input_tensor)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    total = 0\n",
    "    nr_correct = 0\n",
    "\n",
    "    accuracies = []\n",
    "    for (batch_index, (images, labels)) in enumerate(training_set):\n",
    "        accuracy = model.fit(images, labels)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_set):\n",
    "    total = 0\n",
    "    nr_correct = 0\n",
    "    \n",
    "    for images, labels in test_set:\n",
    "        \n",
    "        result = model(images)\n",
    "        \n",
    "        _, predictions = torch.max(result, 1)\n",
    "        total = images.size(0)\n",
    "        nr_correct = torch.sum(predictions == labels).item()\n",
    "                \n",
    "    return nr_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing for model with id:  0\n",
      "0.981\n",
      "0.981\n",
      "0.979\n",
      "0.987\n",
      "0.985\n",
      "0.991\n",
      "0.99\n",
      "0.986\n",
      "0.984\n",
      "0.991\n",
      "0.993\n",
      "0.993\n",
      "0.99\n",
      "0.996\n",
      "0.995\n",
      "0.989\n",
      "0.997\n",
      "0.99\n",
      "0.992\n",
      "0.991\n",
      "Training and Testing for model with id:  1\n",
      "0.973\n",
      "0.986\n",
      "0.981\n",
      "0.986\n",
      "0.993\n",
      "0.986\n",
      "0.983\n",
      "0.987\n",
      "0.987\n",
      "0.992\n",
      "0.997\n",
      "0.988\n",
      "0.986\n",
      "0.989\n",
      "0.987\n",
      "0.982\n",
      "0.993\n",
      "0.994\n",
      "0.991\n",
      "0.992\n",
      "Training and Testing for model with id:  2\n",
      "0.965\n",
      "0.986\n",
      "0.986\n",
      "0.987\n",
      "0.995\n",
      "0.994\n"
     ]
    }
   ],
   "source": [
    "top_models_num = 10\n",
    "epochs = 20\n",
    "models_accuracies = {}\n",
    "\n",
    "time_start = time.time()\n",
    "model_id = 0\n",
    "\n",
    "for model_data in models_params_data[:top_models_num]:\n",
    "    \n",
    "    model_hyper_params = model_data[1] # select the dictionary with the yper params for each model\n",
    "    models_accuracies[model_id] = []\n",
    "    \n",
    "    model = Model(model_hyper_params)\n",
    "    print(\"Training and Testing for model with id: \", model_id)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        train_model(model)\n",
    "        \n",
    "        accuracy = test_model(model, test_set)\n",
    "        \n",
    "        models_accuracies[model_id].append(accuracy)\n",
    "        print(accuracy)\n",
    "        \n",
    "        \n",
    "    model_id+=1\n",
    "\n",
    "#     print(models_accuracies)\n",
    "#     print(\"Training and Testing completed for model with id: \", model_id)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {0: [0.981, 0.984, 0.986, 0.985, 0.987, 0.99, 0.988, 0.985, 0.986, 0.988, 0.99, 0.988, 0.996]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_json = json.dumps(models_accuracies)\n",
    "f = open(\"top_models_accuracies\", \"w\")\n",
    "f.write(params_json)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_range = list(range(1, epochs_+1, 1))\n",
    "\n",
    "colors = ['#04f108', '#f11f04', '#f15704', '#e5f104', '#7af104', '#04f186', '#b2f104', '#043bf1', '#c204f1', \n",
    "          '#f104be', '#f10404']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Top 10 Models Accuracy Scores\")\n",
    "\n",
    "plt.fig(figsize=(5,6))\n",
    "\n",
    "for i in range(epochs):\n",
    "    ax.plot(epoch_range, models_accuracies[i], colors[i], linewidth=1, label=\"Model \"+str(i+1))\n",
    "#     ax.plot(t,models_accuracies[1], \"b-\", linewidth=1, label=\"Model 2\")\n",
    "    \n",
    "ax.legend()\n",
    "ax.set_ylabel(\"Accuracy Score\")\n",
    "ax.set_xlabel(\"Number of Epochs\")\n",
    "plt.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
